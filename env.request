pip install scrapy

scrapy startproject XXX 创建 scrapy 项目

scrapy.cfg: 项目的配置文件
XXX/: 该项目的python模块。之后您将在此加入代码。
XXX/items.py: 项目中的item文件.
XXX/pipelines.py: 项目中的pipelines文件.
XXX/settings.py: 项目的设置文件.
XXX/spiders/: 放置spider代码的目录.

scrapy genspider mydomain[name] mydomain.com[domain_url] 创建 spider

1、出现了403的错误，如下所示：
DEBUG: Crawled (403) <GET https://movie.douban.com/subject_search?search_text=28%E5%B2%81%E6%9C%AA%E6%88%90%E5%B9%B4> (referer: None)
原因是代理被禁止访问，解决方法：
在settings配置文件里修改不设置代理
DOWNLOADER_MIDDLEWARES = {
'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,
}

2、出现了Forbidden by robots.txt的错误

原因是scrapy是遵守robot协议的，在访问网址前会先访问robot.txt来查看自己是否有权限访问。如果网站不允许被爬，就不能访问。
解决方法，设置不遵守robot协议：
ROBOTSTXT_OBEY = False

3、为了启用一个Item Pipeline组件，你必须将它的类添加到 ITEM_PIPELINES 配置
ITEM_PIPELINES = {
   'tutorial.pipelines.TutorialPipeline': 300,
}

// 重复爬取同一个 url
加上第三个参数dont_filter = True
Request(url,callback,dont_filter=True)
如果在 start_requests 函数中 使用 while 1 ： 循环

from ..items import ToutiaoItem 导入 item 类